{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cryptography\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand the Fundamental Concepts of Cryptography\n",
    "```\n",
    "Explain the fundamental concepts of cryptography and how they are used. Cryptography is the process of obscuring or hiding the meaning of information so that unauthorized persons or processes cannot read it or make a useful copy of it. The original information is called plaintext (no matter what form of data it is), which is encrypted to produce ciphertext, which can be transmitted to a recipient or stored for later retrieval. Upon receipt or retrieval, the ciphertext is decrypted to recover the original meaning and the original form of the plaintext. The encryption and decryption processes (or algorithms) require keys; without the keys, no encryption or decryption can occur. Symmetric encryption uses the same key (or a simple transform of it) for encryption and decryption, whereas asymmetric encryption uses different keys that are nearly impossible to derive from each other.\n",
    "```\n",
    "Cryptography brings many capabilities to the information systems designer, builder, user, and owner:\n",
    "\n",
    "* **Confidentiality**: Protect the meaning of information and restrict its use to authorized users.\n",
    "* **Utility**: Map very large sets of possible messages, values, or data items to much smaller, more useful sets.\n",
    "* **Uniqueness**: Generate and manage identifiers for use in access control and privilege management systems.\n",
    "* **Identity**: Validate that a person or process is who and what they claim to be.\n",
    "* **Privacy**: Ensure that information related to the identity of a person or process is kept confidential, and its integrity is maintained throughout.\n",
    "* **Nonrepudiation**: Provide ways to sign messages, documents, and even software executables so that recipients can be assured of their authenticity.\n",
    "* **Integrity**: Ensure that the content of the information has not been changed in any way except by authorized, trustworthy processes.\n",
    "\n",
    "**Encryption** is the process of taking a message written in one set of symbols (and its syntax and semantics) and hiding or obscuring its meaning by changing the way the message is written. **Decryption** is then the process of unobscuring or revealing the meaning of an encrypted message and restoring it so that its original meaning is intact and revealed. The original **plaintext** message or information is encrypted into **ciphertext**, which is then decrypted back to its plaintext form and meaning.\n",
    "\n",
    "**Cleartext** can either mean plaintext or data that is never intended to be transmitted, stored, or used in anything but an unencrypted form with its meaning and value available to anyone to read.\n",
    "\n",
    "**Cryptographic algorithms** are the formal definition of the processes we use to encrypt plaintext into ciphertext and then decrypt ciphertext back to plaintext.\n",
    "\n",
    "![](images/encoding-encrypting-decrypting-decoding.png)\n",
    "\n",
    "At its heart, all cryptography uses substitution and transposition to take the input plaintext and rewrite it in a different set of symbols so that its meaning is hidden. Simple **substitution** encrypts by replacing every occurrence of one symbol in the plaintext with its cipher value (from a table); the symbols can be individual letters, digits, short fixed-length strings of characters, or entire words. Decryption takes each symbol in the ciphertext and uses the same table to look up its plaintext value. **Transposition** changes the order of symbols in the plaintext message (as in the scytale cipher used in ancient Greece).\n",
    "\n",
    "**Cryptography** is the art and science of transforming plaintext information by means of suitable encryption techniques into ciphertext, which can then be decrypted back into matching plaintext. \n",
    "\n",
    "A **cryptographic system** is the sum total of all the elements we need to make a specific application of cryptography be part of our information systems. It includes the algorithm for encrypting and decrypting our information; the control parameters, keys, and procedural information necessary to use the algorithm correctly and any other specialized support hardware, software, or procedures necessary to make a complete solution.\n",
    "\n",
    "* **Cryptography** refers specifically to the use and practice of cryptographic techniques.\n",
    "* **Cryptanalysis** refers to the study of vulnerabilities (theoretical or practical) in cryptographic algorithms and systems and the use of exploits against those vulnerabilities to break such systems.\n",
    "* **Cryptology** refers to the combined study of cryptography (the secret writing) and cryptanalysis (trying to break other people’s secret writing systems or find weaknesses in your own).\n",
    "* **Cryptolinguistics**, however, refers to translating between human languages to produce useful information, insight, or actionable intelligence (and has little to do with cryptography).\n",
    "\n",
    "By defining how the cryptographic systems process the input plaintext, we can get:\n",
    "\n",
    "* **Character or symbol ciphers** use individual symbols in the plaintext as the unit to encrypt and decrypt, much like the simple, classical substitution and transposition ciphers did.\n",
    "\n",
    "\n",
    "* **Block ciphers** take the input plaintext as a stream of symbols and break it up into fixed-length blocks; each block is then encrypted and decrypted as if it was a single (larger) symbol. A block of $64$ bits ($8$ eight-bit bytes) can be thought of as a $64$-digit binary number, which is what the encryption algorithm would then work on. Block ciphers typically have to pad the last block of a fixed-length plaintext message (such as a file or an email) so that each block has the required length.\n",
    "\n",
    "\n",
    "* **Stream ciphers** are symmetric encryption processes that work on a single byte (sometimes even a single bit) of plaintext at a time, but they use a pseudorandom string (or keystream) of cipher digits to encrypt the input plaintext with. Stream ciphers typically use simple operations, such as exclusive-or, to encrypt each bit or byte. These operations run very fast (perhaps each encryption taking a few nanoseconds). Stream ciphers by design can work on any length of input plaintext. The keystream generator is a function (implemented in hardware, software, or both) that uses a seed value (the encryption key itself) as input, producing encryption values to be combined with each bit or byte of the input plaintext. Stream ciphers like RC4 find widespread use in mobile communications systems such as cell phones, Wi-Fi, and others, in which the plaintext input is often of unbounded length.\n",
    "\n",
    "A **cryptographic algorithm** defines or specifies a series of steps - some mathematical, some logical, some grouping or un-grouping of symbols, or other kinds of operations—that must be being applied, in the specified sequence, to achieve the required operation of the system. Think of the algorithm as the total set of swap rules that you need to use, and the correct order to apply those rules in, to make the cryptographic system work properly. The basic processes of substitution and transposition can be repetitively or iteratively applied in a given cryptographic process. The number of rounds that an algorithm iterates over is a measure of this repetition. A combination of hardware and software features can implement this repetition.\n",
    "\n",
    "Encryption and decryption processes can suffer from what we call a **collision**, which can render them unusable. This can occur if one of the following happens:\n",
    "\n",
    "* Two different plaintext phrases should not map (encrypt) to the same ciphertext phrase; otherwise, you lose the difference in meaning between the two plaintext phrases.\n",
    "* Two different ciphertext phrases should not map (decrypt) to the same plaintext phrase; otherwise, you have no idea which plaintext meaning was intended.\n",
    "\n",
    "We talk about the **key strength** as a way to measure or assert how much effort would be required to break (illicitly decrypt) a cleartext message encrypted by a given algorithm using such a key. In most cases, this is directly related to the key size, defined as how many bits make up a key. Another way to think of this is that the key strength determines the size of the key space - the total number of values that such a key can take on. Thus, an $8$-bit key can represent the decimal numbers $0$ through $255$, which is like saying that an 8-bit key space has $256$ unique values in it. SSL uses a $256$-bit key as its session key (to encrypt and decrypt all exchanges of information during a session), which would mean that someone trying to brute force crack your session would need to try $2256$ possible values (that's a $78$-digit base-$10$ number) of a key to decrypt packets they’ve sniffed from your session.\n",
    "\n",
    "**Key distribution and management** become the biggest challenges in running almost any cryptographic system. **Keying material** is a term that collectively refers to all materials and information that govern how keys are generated and distributed to users in a cryptographic system, and how those users validate that the keys are legitimate. **Key management** processes govern how long a key can be used and what users and systems managers must do if a key has been compromised (presumably by falling into the wrong hands). **Key distribution** describes how newly generated keys are issued to each legitimate user, along with any updates to the rules for their period of use and their safe disposal. \n",
    "\n",
    "The term **cryptographic protocols** can refer to two different sets of processes and techniques. The first is the use of cryptography itself in the operation of a cryptographic system, which typically can refer to key management and key distribution techniques. The second usage refers to the use of cryptographic systems and techniques to solve a particular problem.\n",
    "\n",
    "A **cryptographic module** is any combination of hardware, firmware, or software that implements cryptographic functions. \n",
    "\n",
    "### Hashing\n",
    "\n",
    "```\n",
    "Differentiate between hashing and encryption. Hashing is a one-way encryption process: plaintext goes in, a hash value comes out, but you cannot reverse this to “un-hash” a hash value to get back to the original plaintext. Hashing takes a plaintext message and uses an encrypting hash algorithm to transform the plaintext into a smaller, shorter value (called the hash or hash value), which must be unique to the input plaintext. The hash algorithm should make it impossible to decrypt the hash value back into the plaintext, without any way to determine the meaning of a particular hash value. By contrast, the purpose of non-hashing encryption is to safely store or communicate plaintext with its meaning hidden for storage and transmission so that the meaning can later be derived by means of the right decryption algorithm and key. Encryption for storage and communication is thus part of a two-way process.\n",
    "```\n",
    "\n",
    "Hashing provides a way to take a very large set of expressions (messages, names, values, etc.) and map them down to a much smaller set of values.\n",
    "\n",
    "Hashing provides many advantages in information systems design that stem from its ability to uniquely generate a numeric value that can represent arbitrary alphanumeric data (such as individual names or street addresses, part numbers, or drug names). These hash values can be stored in tables as relative offsets or pointers into very large files, eliminating the need to read every record to see if it's the one you actually need to use. Hashing the entire contents of a file produces a long-form error detection and correction code by reapplying the hash function and comparing that resultant hash value to the one stored with the file; a mismatch indicates the file may have been corrupted or changed. These are sometimes called **digital fingerprints** or **checksums** when used to detect (and possibly correct) errors in file storage or transmission. Hashing can also be applied to an entire message, producing a secure message hash or message digest. Since messages are typically of variable length, the message digest is fixed length, which makes them easy to use in file systems, communications systems, and security systems.\n",
    "\n",
    "Hash algorithms transform the long key into a hash key or short key, where the long keys can be drawn from some arbitrarily large set of values (such as personal names) and the short key or hash key needs to fit within a more constrained space. The hash key, also called the hash, the hash value, the hash sum, or other term, is then used in place of the long key as a pointer value, an index, or an identifier. Two main properties of hash functions are similar to those of a good encryption function:\n",
    "\n",
    "* The hash function must be one way: there should be no computationally feasible way to take a hash value and back-compute or derive the long key from which it was produced.\n",
    "* The hash function must produce unique values for all possible inputs; it should be computationally infeasible to have two valid long keys as input that produce the same hash value as a result of applying the hash function.\n",
    "\n",
    "Notice that both hashing and encryption must be one-to-one mappings or functions - no two input values can produce the same output value. But encryption must be able to decrypt the ciphertext back into one and only one plaintext (the identical one you started with).\n",
    "\n",
    "![Hashing vs. Encryption as Functions][images/hashing-vs-encryption-as-functions.png]\n",
    "\n",
    "Like encryption algorithms, hash algorithms need to deal with collisions (situations where two different long key inputs can hash to the same hash value). These are typically addressed with additional processing stages to detect and resolve the collision.\n",
    "\n",
    "Hash algorithms may make use of a salt value to initialize the calculations. This is typically a random (well, pseudorandom) value that is included with the input long key; if the hash algorithm is dealing with a $256$-byte long key, a two-byte salt value effectively has the algorithm work on $258$ bytes. This offers significant protection against rainbow table or dictionary-based attacks on hashes by making the attacker have to precompute a significantly larger table of hashed values.\n",
    "\n",
    "A number of published standards define secure hash functions for use in various kinds of information security systems. The SHA series of Secure Hash Algorithms, published by the NSA, is one such series; the original SHA-0 and SHA-1 standards have been shown to be vulnerable to collision attacks and are being disbanded for use with SSL.\n",
    "\n",
    "If an algorithm is **deterministic** - given the same input and series of events, it always produces the same result.\n",
    "\n",
    "If we use a deterministic algorithm to produce this set of numbers, using a seed value as a key input, we call such sets of numbers **pseudorandom**: the set as a whole exhibits statistical randomness, but given the nth value of the sequence and knowing the algorithm and the seed, the next element of the sequence - the $(n + 1)$th value - can be determined.\n",
    "\n",
    "**Entropy** is a measure of the randomness of a system.\n",
    "\n",
    "### Salting\n",
    "\n",
    "```\n",
    "Explain the basic hashing algorithms and the role of salting in hashing. Hashing algorithms treat all input plaintext as if it is a series of numbers and use techniques such as modulo arithmetic to transform potentially large, variable-length inputs into fixed-length hash values. When the function is chosen correctly, the change of a single bit in the input will produce a significantly different hash value. This provides a fast way to demonstrate that two sets of input (two files, for example) are either bit-for-bit identical or they are not. It should not be possible to take a hash value and reverse-calculate what the input plaintext was that produced it. To improve the strength of a hash function, a large random number is added to the input plaintext as additional bytes of input. This makes it much harder for brute force attacks to attempt to break a hash value back to its original plaintext.\n",
    "```\n",
    "### Symmetric/Asymmetric Encryption/Elliptic Curve Cryptography (ECC)\n",
    "\n",
    "```\n",
    "Explain the important differences between symmetric and asymmetric encryption algorithms. Symmetric encryption uses the same key (or a simple transform of it) for encryption and decryption. The underlying mathematical operations are ones that can run in reverse so that the ciphertext can be decrypted back to the form and content of the original plaintext. Once compromised, this key can be used to decrypt all previously encrypted ciphertext—there is no forward privacy or secrecy. Asymmetric encryption uses a very different mathematical construct to encrypt than it does for decrypting; it is required that there be no computationally feasible or doable way to take ciphertext and solve for the original plaintext without having both the corresponding decryption algorithm and the decryption key. There should also be no way to mathematically derive the decryption key from the encryption key. Asymmetric encryption, when implemented with computationally difficult algorithms using very large numbers as factors and keys, provides inherently better security than symmetric encryption can, given the same size keys. It can also provide forward secrecy (protect previously encrypted ciphertext from being decrypted) when keys are changed or compromised. Asymmetric encryption and decryption are compute-intensive, using a lot of processing time, whereas symmetric encryption can be built to run very fast in hardware, software, or both. Thus most public key infrastructures use asymmetric encryption while establishing a session key and then use symmetric encryption, using that session key for the bulk of the session’s communication.\n",
    "```\n",
    "\n",
    "Symmetric encryption algorithms have the greatest challenges with key management and key distribution. Symmetric encryption not only uses the same key (or a simple transform of that key) for encryption and decryption; it also provides no forward secrecy - which means that when a key is compromised, that compromised key can always be used to decrypt any ciphertext that was produced with that key.\n",
    "\n",
    "As you'll see later, asymmetric encryption still uses keys; those keys still must be protected. And even though you publish your public key (when using hybrid encryption systems and the public key infrastructure for key exchange), your private key still represents the single most important secret that you must keep.\n",
    "\n",
    "Any cryptographic system has to deal with key **revocation** - informing all users that a particular key is no longer valid and that it should not continue to be used.\n",
    "\n",
    "**Zeroization** is the process by which cryptologic systems are cleared of all keying materials, plaintext, ciphertext, control parameters, and sometimes even their software and firmware. This process serves two main purposes: it restores the device to a clean initial state, and it removes any information that might possibly be used to break the encryption scheme, decrypt previously encrypted messages, or derive the encryption key to use for later decryption of subsequent messages.\n",
    "\n",
    "#### Symmetric Key Cryptography\n",
    "\n",
    "Symmetric key cryptography uses the same key to encrypt and decrypt the data being exchanged or protected. The algorithms for symmetric key cryptography typically run very fast - this type is suitable for encrypting high data rate streaming services, for example, or for protecting very large databases at rest or in motion.\n",
    "\n",
    "Key distribution and key management are the Achilles’ heel of symmetric key encryption strategies. Every sender-receiver pair needs to exchange keys, which means for n users in a key exchange system you have n2 key exchanges to manage—and to update when you have to retire one key and replace it with another. With so many keys in motion, it becomes probable that keys may be intercepted and surreptitiously copied in transit, storage, or use. Brute force or other computational techniques can defeat these encryption schemes given sufficient computing resources.\n",
    "\n",
    "#### Asymmetric Key (or Public Key) Cryptography\n",
    "\n",
    "The asymmetric key (or public key) cryptographic set of algorithms and systems uses one key for encrypting the plaintext, and a very different key for decrypting the resultant ciphertext back to useful plaintext. This typically means that very different algorithms are used to encrypt and decrypt. The strength of asymmetric key cryptography rests on the assertion that it is computationally infeasible to use the encryption key to calculate the decryption key or to use the decryption key to calculate the encryption key, even if the details of the algorithms are known. The asymmetric encryption algorithms are often called **trapdoor functions**, in that you can fall down through an open trapdoor, but you cannot fall backup through it.\n",
    "\n",
    "Public key distribution systems rely on the near impossibility of computing one of a pair of keys given the other. This lets users publish (or make publicly available) one key (the public key) while keeping the corresponding key secret and protected (or private). \n",
    "\n",
    "#### Hybrid Cryptosystems\n",
    "\n",
    "Hybrid cryptosystems use multiple approaches to encrypt and decrypt the plaintext they are protecting. The most common hybrid systems are ones that combine asymmetric and symmetric algorithms using:\n",
    "\n",
    "* **Key encapsulation** processes, which are typically built with public key infrastructures (PKIs) to handle key exchange.\n",
    "* **Data (or payload) encapsulation** processes, which use more runtime-efficient symmetric key algorithms.\n",
    "\n",
    "\n",
    "\n",
    "### Non-Repudiation (e.g., Digital Signatures/Certificates, HMAC, Audit Trail)\n",
    "\n",
    "```\n",
    "Know how to use cryptography to provide nonrepudiation. Digitally signing documents, files, or emails makes it exceptionally difficult for a sender to claim that the file the recipient has is not the file that they sent or to deny sending it at all. Using digital signatures to prove receipt and use of files by the addressee or recipient, however, requires some form of digitally signed receipt process, which most email systems cannot support. However, add-on systems for email do provide this, and EU standards have been supporting their adoption and use as part of secure e-commerce. Some national postal systems and a growing number of Internet service providers now make such capabilities available to users.\n",
    "```\n",
    "### Encryption Algorithms (e.g., AES, RSA)\n",
    "\n",
    "```\n",
    "Explain the difference between character, block, and stream ciphers. Character ciphers encrypt and decrypt each single character or symbol in the input plaintext, such as is done by a simple alphabetic substitution cipher; the encryption key is used to encrypt (and decrypt) each character. Block ciphers encrypt and decrypt fixed-length groups (blocks) of symbols or bytes from the input plaintext, typically in fixed-length blocks, which are then encrypted via transposition, substitution, or both; block ciphers may also transpose blocks, and multistage block encryption can do that at any stage in the process. The keys for block ciphers are applied to each block for encryption and decryption. Stream ciphers treat the input plaintext and the key as if they were continuous streams of symbols, and they use one element of the key to encrypt one element of the plaintext. Stream ciphers must use a key whose length is longer than the input plaintext and is random across that length to prevent attacks against the ciphertext.\n",
    "```\n",
    "\n",
    "```\n",
    "Understand how encryption strength depends on the size of keys and other parameters. The simplest way to break an encryption system is to capture some ciphertext outputs from it, and using its known or assumed decryption algorithm, try every possible key and see if a presumed cleartext output is a meaningful message. Since even pure binary cleartext files (executable programs, for example) contain a lot of error checking and parity information, if a presumed cleartext output is error free, it probably is meaningful and might even be what the attacker is looking for. Key length determines how many possible keys must be tried—keys of 8-bit length require trying only 256 possible keys, for example. The larger the key, the larger the search space of possible keys. Using large, random salt or seed values as part of the encryption and decryption effectively enlarges that search space again. If the encryption and decryption algorithms depend on numbers, such as integer factors or exponents, the larger these values, again, the larger the search space.\n",
    "```\n",
    "### Key Strength (e.g., 256, 512, 1024, 2048 Bit Keys)\n",
    "### Cryptographic Attacks, Cryptanalysis, & Counter Measures\n",
    "\n",
    "White hat cryptanalysis can help pinpoint weaknesses in key generation, key management and distribution, or even in the algorithms themselves. This might lead us to redesign these systems and processes or to provide other processes to reduce the risk of harm if we cannot affordably strengthen our cryptosystems. \n",
    "\n",
    "Black hats may use many of the same tools and techniques and read many of the same technical journals, wiki pages, and books that the white hats depend on as they try to find and exploit vulnerabilities in our cryptosystems and their use.\n",
    "\n",
    "The white hats might include:\n",
    "* Law enforcement and national security organizations when taking captured devices or systems (or ones seized under a court order or other lawful process) and examining them for evidence\n",
    "* Cryptosystems engineers, designers, and builders when attacking their own products or other systems provided to them under contract as part of systems vulnerability assessments\n",
    "* Ethical hackers employed or under contract as part of penetration testing or system vulnerability assessment activities\n",
    "* Students and teachers conducting ethical hacking and cryptanalysis as part of learning activities\n",
    "\n",
    "The black hats list would include hostile national intelligence, security, and military services; business competitors (at home or abroad) willing to commit industrial espionage; private investigators, journalists, or others willing to break the law to seek incriminating, embarrassing, or other information they can use; and the whole gamut of criminal individuals and organizations.\n",
    "\n",
    "#### Brute Force and Dictionary Attacks\n",
    "\n",
    "Lexically based ciphers first taught us that given enough cryptanalysts and enough dictionaries, we could probably break any such cipher system. In essence, the attacker makes assumptions about the cryptosystem being used and about its control parameters, and then uses randomly generated plaintext to see if its encrypted results match any substring in captured ciphertext. Such “brute force” (try every possibility—there’s bound to be a winner in there somewhere!) approaches are also used as password-cracking schemes. Consider the typical four-digit personal identification number used on automated teller machine (ATM) and online banking systems. Only 10,000 guesses are the most required to break into your account! Of course, we rely on our banks to notice this and shut off the card after a much smaller number. Social engineering approaches can often find information that drastically reduces that search space.\n",
    "\n",
    "Dictionary attacks often rely on precomputed tables of values, and of course, the larger the key space, the larger these tables have to become, requiring both more storage and faster storage access to be able to apply a brute force approach in a reasonable amount of time.\n",
    "\n",
    "#### Side Channel Attacks\n",
    "\n",
    "Since every cryptosystem has to have some kind of hardware to run on—even it if is purely implemented in software—that hardware can be observed to see if it offers any kind of signatures that indicate something about the internals of the algorithms being used. Side channel attacks get their name because the channel the attacker is listening to is alongside the channel that the cryptosystem is supposed to be operating in and are limited only by the attacker’s imagination. All start from the premise that computing systems show tiny variances in some kind of physical or operational signature based on the actual data being processed; if you can observe enough of these variations and correlate them to the data stream itself, perhaps you’ve found an exploitable weakness. Some possibilities include:\n",
    "\n",
    "**Cache attack** Monitoring the contents and use of processor or I/O board caches or software-managed caches in virtual machine and cloud systems.\n",
    "\n",
    "**Timing attack** Tightly monitoring the time each step takes.\n",
    "\n",
    "**Power monitoring or power variation attack** Monitoring power usage by specific hardware elements in the cryptosystem. Many RSA implementations are vulnerable to fluctuations in electrical power.\n",
    "\n",
    "**Electromagnetic attack** Measuring the tiny (sometimes not so tiny!) radio waves emitted by elements of the cryptosystem.\n",
    "**Acoustic analysis** Measuring mechanical vibrations in system elements.\n",
    "**Differential fault analysis** Introducing faults into your test copy of the system and seeing what that reveals.\n",
    "**Data remanence** Well-designed cryptosystems should not leave partial or intermediate results, pad counts, etc., lying around in their innards after processing has been completed; most, however, do leave something, somewhere, which is why system zeroization is important. These partial values can be swept up in a test environment and may be revealing.\n",
    "Software-initiated fault attacks By attacking other aspects of the system that hosts the cryptosystem, faults in the host environment or the cryptosystem may be triggered.\n",
    "**Optical attacks** Passive optical attacks that work by reading the disk activity lights or the lights on your routers and modems might seem old hat, but they can work. Attackers can also physically open the hardware of a cryptosystem under test, open the microchips, and use instruments to look for stray photons emitted as the system is operating. Active attacks involve using light, lasers, or even scanning electron microscopes to interact with the cryptosystem’s circuits, similar to injecting noise or test signals, to observe the results.\n",
    "**Branch predictor attacks** Using software engineering analysis tools to predict when and how branches in the algorithm will be executed, and then using those predictions to reveal characteristics of the data being processed.\n",
    "Although no one side channel attack will reveal everything, the combination of these and other possible investigative techniques could in fact lead to breaking the cryptosystem under test.\n",
    "\n",
    "#### Numeric (Algorithm or Key) Attacks\n",
    "Almost every cryptosystem depends on logical assertions that lead to concluding that “system X is unbreakable provide that conditions A, B, and C hold true.” Consider all of the algorithms that depend on very, very large prime numbers. If your system for finding the next three very large prime numbers has a bug in it and occasionally picks a value that is not prime, this can lead to an unintentional backdoor in your trapdoor function and allow attackers to crack your encryption by defeating the algorithm. (This is a front channel attack, as opposed to the side channel attack described earlier.) Much like purely random numbers that turn out not to be very random at all, any logical or mathematical error in the way that the cryptosystem is implemented can lead to incorrect operation and a possible exploitable weakness.\n",
    "Without going into the math, some of the names you may encounter as you look at such mathematically based attacks or the weaknesses they are based on include the following:\n",
    "* Small values for exponents and other control parameters in algorithms\n",
    "* Chinese Remainder attacks This theorem (which dates from the third century CE) can be applied when some parts of the control parameters can be guessed, or when too many users share same plaintext and some of the same parameters (such as e, but not p, q, and therefore n).\n",
    "* Coppersmith’s attack A form of Chinese Remainder attack, which also can work when attacker knows part of the secret key.\n",
    "* Broadcast attacks The attacker sends the same plaintext or the same ciphertext to multiple recipients, collects (or intercepts) responses, and analyzes the results.\n",
    "* Related message attack If two ciphertext messages differ in part in some known or understandable ways, other analysis may reveal more about the keys or control parameters in use.\n",
    "* Short padding attacks Most cryptosystems have to deal with padding out variable-length message content so that the encryption and decryption algorithms can work on expected block sizes. Incorrect or short padding can open an exploitable weakness.\n",
    "* Algorithmic weaknesses Some algorithms are just not as logically or mathematically strong as they claim to be (think about DES).\n",
    "* Usage weaknesses Patterns of use that reveal information about algorithms, keys, or content.\n",
    "* Faulty prime numbers in key generation Values that actually aren’t prime, or two primes that aren’t far enough apart (on the number line) to meet strong encryption needs.\n",
    "* Pseudorandom number weaknesses Too small, or not random enough (can predict their generator’s output sequence).\n",
    "* Anticipated or predicted plaintext can also be useful in such attacks, as well as using a related message attack, in which two ciphertexts thought to be very similar can be compared and analyzed to possibly reveal weaknesses in the cryptosystem.\n",
    "* And many more.\n",
    "\n",
    "#### Traffic Analysis, “Op Intel,” and Social Engineering Attacks\n",
    "\n",
    "We’ll group these three attack vectors into one group, not because they use similar analytical attack processes, but because they often exploit the human frailties in our organizations and the ways we put cryptographic systems to work. They are useful as part of an attacker’s ongoing reconnaissance efforts, and as such they can quite often break the protection that cryptosystems were supposed to provide.\n",
    "\n",
    "Operational intelligence is the gathering of information and insight by watching how your organization operates, at the fine-grained, step-by-step process or task level, and looking for patterns. Observing that a Coast Guard unit often places phone orders for dozens of pizzas or other meals to be delivered might, for example, be a tip-off that a cutter is about to launch to do an intercept of a suspect vessel at sea. Traffic analysis looks at how communications ebb and flow across the organization, even if the content is encrypted; changes in these patterns can often be reliable predictors of changes in behavior. Social engineering encompasses almost any effort to learn about the people in the organization and find exploitable weaknesses via those people. Sadly, the greatest human strength we have—that we are “herd animals” and we live best by helping others in our “herd”—is the most exploitable social engineering weakness that we have. Think of the total of these intelligence and reconnaissance processes as reverse-engineering how your organization gets its work done, finding exploitable vulnerabilities along the way. If this all sounds like what you should have been doing during the vulnerability analysis phase yourself, you’d be right!\n",
    "\n",
    "We’d like to think that we’ve come a long way since the days when journalists could construct an organizational map of the Central Intelligence Agency headquarters by starting with the phone number listed in the public phone records, and just war dial numbers around that, asking each person who answered who they were and what office they were in. The infamous “I’m from IT, could you let me log on as you?” trick is still used for one reason only: because it works. So-called dumpster diving, going through the trash thrown out by a target organization, is still quite revealing (if a bit messy). This is especially useful when planning algorithmic attacks that need fragments of ciphertext, expired keying material, user or maintenance documentation (about the cryptosystems or other systems and processes), customer and subscriber information, or even equipment declared surplus and sent to the salvage yard or the dumpster.\n",
    "\n",
    "In nearly all cases, these traditional espionage techniques still work because people and organizations tend to take shortcuts, make mistakes, or make incorrect assumptions. We cannot overemphasize this point! Product and systems implementations get rushed, because the deadlines are important; design assumptions can be inadequately tested or validated; and risk assessments can and are often curtailed or done only in a summary fashion.\n",
    "\n",
    "#### Massively Parallel Systems Attacks\n",
    "In many, if not all, cryptographic systems, we assume that attackers will find it computationally infeasible to successfully apply brute force, pattern matching, or many other numerical or number theory–based attack approaches. This assumption about what is feasible—whether it is affordable or even doable—is part of that race against time we talked about earlier. Consider the the arguments over key length when DES was being created and competed, and how AES has had to push to even longer keys, as just one indicator. National security and intelligence services have long been one of the biggest drivers on the supercomputer and massively parallel computing market (and the ones with the deepest pockets to pay for such systems, typically), so we already have many examples of using such systems to break encryption schemes. (This is nothing new; if you think about it, the Bombe that Alan Turing and his team built for the British during World War II was far more expensive, physically larger, and demanded a larger team of talented brainpower than the cryptosystem they were trying to defeat. Compared to Enigma, the Bombe was a supercomputer of its day.)\n",
    "\n",
    "Massively parallel architectures are also readily available to the rest of us, especially if we have a bit of money to invest. As the Stone Soupercomputer project at Oak Ridge National Laboratories demonstrated, clever engineering can take most any set of computers and mesh them together to solve complex numerical problems on the cheap. Academics (even high schools) learned from this example, as did the hacking community. And of course, we’ve seen that massive zombie botnets can easily be organized and used to conduct distributed denial of services attacks. If it hasn’t happened already, the time when a massive zombie botnet figures prominently in an attack on a cryptographic system, its algorithms, or its keys is not very far away.\n",
    "\n",
    "#### Supply Chain Vulnerabilities\n",
    "As you saw when we looked at hierarchies of trust, virtually every element of our IT systems comes from some supplier, who got it from some manufacturer, who built it out of parts and subsystems built by other companies, and so on. Every element of that value chain is a potential point of vulnerability, a place where otherwise trustworthy designs can have backdoors inserted or key parameters tweaked to create a weakness. Intelligence services have long been adept at surreptitiously modifying equipment, and later software, while it was en route to a target that they wished to gain insider access to or manipulate in some fashion.\n",
    "\n",
    "The dangers of an inadequately protected supply chain are not just limited to surreptitious manipulation (legal or otherwise) by outsiders. Many of the attacks against cryptosystems exploit errors in design and use, and one such logical error is if too many devices in too many client or server systems are using the same prime numbers. As a systems administrator, you usually can replace the default administrator username and password, but on most commodity devices like modems, switches, routers, firewalls, VPN systems, or even printers, projectors, and VOIP systems, you’ll have a hard time getting at the key parameters that dictate how those devices initiate and perform as elements in your cryptographically protected systems.\n",
    "\n",
    "Does that sound farfetched? In 2013, four researchers documented just how prevalent this “common prime use” is in the IT industry, finding that the same common primes were integral to devices from over 30 manufacturers. Since then, one of this team, Nadia Heninger, has been quite outspoken about how national security services don’t have to break everybody’s codes to read everybody’s information as a result of this supply chain weakness.\n",
    "\n",
    "Supply chain weaknesses in IT security and cryptography are at risk of being exploited against us, whether by criminals, terrorists, foreign governments, or our own governments. A closer read of the reporting on the Edward Snowden information leaks, back in 2013, reveals that NSA had not only actively been soliciting the cooperation of information systems technology and services providers to build its Total Information Awareness system; it also shows how successful other governments had been at exploiting known supply side vulnerabilities.\n",
    "\n",
    "#### The “Sprinkle a Little Crypto Dust on It” Fallacy\n",
    "The last vulnerability we’ll mention is more of a mental failure than a systems or technology vulnerability. Far too many people—experts and neophytes alike—think that the obvious answer to our information security needs is just to encrypt everything in sight—and most things that are not in sight. We cannot blame people for thinking this way when we readily acknowledge the need for security for data in motion, in use, and at rest.\n",
    "\n",
    "The bad news is that some software development management methodologies seem to promote sloppy software development and testing, particularly when the priority is placed on meeting user needs on time regardless of any possible errors in the implementation of that software. It is in such environments that we sometimes see simple encryption processes (perhaps overly simple!), downloaded from someplace on the Web, incorporated into systems with little end-to-end consideration of what the real security needs are and the steps necessary to achieve them.\n",
    "\n",
    "The good news is that there are well-established, well-understood, and proven methodologies for developing software in ways that earn high assurance that the software does what it needs to, and nothing else, and that includes keeping data properly secure at all times. Good software design frameworks that encourage secure code development, such as the Open Web Application Security Project (OWASP), are a great place to start, but without the end-to-end commitment and support of the development management team, frameworks are not enough.\n",
    "\n",
    "It takes dedication, forethought, time, and effort to apply sound systems engineering and software engineering methods up front; it’s not free to “bake in” the safe and secure computing we need up front as we build our systems, applications, services, or even Internet of Things (IoT) products and gadgets. Much like any kind of product quality approach, too many businesses seem to believe that there’s never enough money or time to do it right the first time, and the ones that usually decide this hope to have moved on to other pastures when someone else has to spend the time and money to do it over again, hopefully better.\n",
    "\n",
    "#### Physical Countermeasures\n",
    "The physical security of your IT systems is the place to start. To the best degree possible, seek to restrict physical access to your Internet service provider’s (ISP’s) point of presence, your communications interfaces (such as modems and routers), and any other on-premises servers and systems. In doing so, your main concern is to prevent unauthorized modifications to hardware, firmware, and control settings; you also want to restrict as much as possible the ability of a stranger to attach a device anywhere on your system, such as a network sniffer or tap.\n",
    "\n",
    "You may also want to inspect all electrical power connections to ensure that no power line–monitoring taps have been surreptitiously added. Uninterruptible power supplies and power conditioning equipment can protect your cryptographic systems from natural and man-made undervoltage, overvoltage, noise, or other power line–injected signals.\n",
    "\n",
    "Systems configuration management information should also be physically protected. Keep such documentation, log analysis reports, and so forth in a locked container, and restrict access to this information to people with the right need to know.\n",
    "\n",
    "The cryptographic elements of end-user systems, servers, and communications systems may need to be periodically zeroized or reset so that any potential leaks or data remanence can be reduced or eliminated. For most small office situations that do not have dedicated cryptologic systems, this can usually be accomplished by a thorough cold boot of systems—but be careful, as many systems have “fast boot” capabilities that actually restart the system from the way it was when it was last shut down. This can lead to data remaining in the system in a variety of ways. (Although you might think of clearing the memory as a logical operation, it usually does take a physical action to accomplish it—even if that’s a manually invoked power-on reset.)\n",
    "\n",
    "Disposal of systems components, documentation, log files, and all other information assets will ultimately lead to some physical item (such as a disk, a document, or a system) being thrown away. Your information classification guide, which you should have developed during your risk assessments, should guide you in determining which assets need destructive zeroization or clobbering and which can be safely disposed (possibly for salvage value).\n",
    "\n",
    "#### Logical Countermeasures\n",
    "Assuming you’ve done a thorough vulnerabilities assessment and already addressed the most compelling of the common vulnerabilities your systems were exposing, dealing with the logical threats to your cryptographic systems mainly involves three sets of actions—key and parameter management, certificate management, and enforcement of user-level requirements:\n",
    "\n",
    "* Management of cryptographic keys, seeds, control parameters, etc., should reflect the strongest level of protection that fits within any runtime performance constraints or targets your organization has established. Establish procedures that control how you decide to make changes, as well as how you control and audit that changes are made correctly.\n",
    "\n",
    "* Your organization may provide its own local CA and issue end-user certificates to individuals or work units, or it may rely on the public key infrastructure completely and the CAs built into the browsers and other systems elements you’re using. Either way, you’ll need policies and procedures for handling certificate issuance and expiration, and quite possibly want to use software-enforced policies that control how end users can override any certificate validation issues they encounter.\n",
    "\n",
    "* Your organization will no doubt write administrative policies that dictate acceptable use, control data exfiltration, and specify user privileges, auditing, and access control, just to name a few. Many of these require that users follow the policies’ instructions and properly use protected systems, some of which involve use of cryptographically protected systems elements. You can use software-defined policies or other logical controls to help enforce these protections.\n",
    "\n",
    "#### Administrative Countermeasures\n",
    "We cannot overemphasize that the number one, most important administrative countermeasure is configuration management and control. With a well-established, documented systems security baseline in your hands, you can quickly determine that a small office, home office (SOHO)-quality Wi-Fi router at the edge of your campus has had its firmware hacked by somebody; you can also verify that despite the lock on the wiring closet door being securely locked, someone has been in there playing around with your infrastructure!\n",
    "\n",
    "The next most important administrative countermeasure is getting your people trained, motivated, and on side with your team. Initial and follow-on training, education, and motivation are imperative to transforming your people risk, yet doing so in ways that keep them customer-focused and engaged, and helpful to the degree their jobs and your team need. Having everyone on the staff know that modern IT systems use all sorts of cryptographic techniques to enforce access control, for example, can be a great way to build trust and confidence; most of your workforce, however, probably has no need to know how you manage certificates or keys.\n",
    "\n",
    "#### Timing Is Everything\n",
    "One final set of countermeasures remains in your organization’s hands: frequent change. You control when passwords must be updated, when caches must be flushed, and when keys must be reset or certificates revalidated or reissued. You control how often (or on what irregular basis) you attempt partial or complete vulnerability assessments, including penetration testing.\n",
    "\n",
    "Classical encryption failed as often as it did because it could easily become predictable. Predicable patterns can drastically reduce the search space in which attackers have to hunt, poke, or attempt to break your encryption; patterns help traffic analysis find more data and more patterns.\n",
    "\n",
    "Be surprise tolerant. Go beyond expecting the unexpected, and try to think ahead of your own business processes. Mix things up; change your rhythms; alter your operational signature.\n",
    "\n",
    "#### Pervasive and Homomorphic Encryption\n",
    "Securing data at rest, in motion, and in use provides an exceptional set of challenges to systems designers. Two distinctly different approaches to this problem address the in use aspect by asking whether the data actually must be decrypted—presented to users in plaintext form—in order to be put to use.\n",
    "\n",
    "Pervasive encryption, as IBM calls it, is one approach that tries to keep sensitive information always encrypted, even when it is being used or displayed. This may dictate extensive changes to information systems architectures, from central systems to end-user devices, as well as changes to the ways we use our systems and information. Pervasive encryption may not be the right, or most cost-effective, answer for each need.\n",
    "\n",
    "**Homomorphic encryption** demonstrates that with the right choice of encryption algorithms, complex data analytics can be performed on many individually encrypted data items to produce a meaningful, aggregate answer—without needing to decrypt any of the input data and without revealing its plaintext or exposing it to attack. (Homomorphic means that things have similar forms but different structures; set theory uses it to describe how the results of performing operations on elements of one set are mapped to the results of applying the corresponding operations to associated members, or images, in a second set. This does not necessarily mean that the reverse mapping can be done.) Individual patient medical data, for example, might be stored in individually encrypted records within many different clinics and care provider applications platforms; if all of these platforms were hosted in the cloud, a different application could access all of that data and draw inferences and conclusions about it without revealing PII or individual patient medical information. This could provide a near-real-time health alert system, detecting the possible outbreak of contagious diseases or spotting a possible toxic exposure event, much earlier than is currently possible. (ElGamal encryption is well suited to use in such homomorphic encryption applications.)\n",
    "\n",
    "#### Quantum Cryptography and Post–Quantum Cryptography\n",
    "Over the last 10–15 years, quantum computing and quantum cryptography have continued to move out of the theoretical literature and into various technology demonstrator systems. It’s quite likely that the next 10 years will see more and more demonstrators become market-worthy technologies. As an SSCP, you won’t be expected to know the physics and the math that make them the unique, new approaches that they are, but you will no doubt need to become more and more familiar with them over time.\n",
    "\n",
    "In the physical sciences, a quantum is the smallest unit of something that can exist. The ancient Greeks thought that this indivisible bit of matter was the atom, but over the last 200-plus years, we’ve continued to split the atom and its subatomic parts into finer and finer pieces. Quantum mechanics, the study of the behavior of the individual quanta of matter, has some very strange effects associated with it. One of these is that whenever you try to measure something about a quantum, the act of measuring interferes with it and changes the state of that quantum. The other is that when you prepare two (or more) quanta in a particular way, their states (their spin direction and orientation, for example) can become entangled, which means that if you physically separate them and force one to change, the other entangled quantum immediately changes state to match. This entanglement phenomenon has sometimes been called “spooky action at a distance.”\n",
    "\n",
    "#### Quantum Computers as Part of Cryptographic Systems\n",
    "\n",
    "Quantum key distribution (QKD) systems can make use of the measurement effect to alert users that a third party has attempted to observe a key. This makes it ideal for one-time pad encryption systems, and in fact, it can work quite well with AES and other symmetric encryption systems as a result. QKD requires special protocols, two of which are the BB84 (developed by Charles Bennett and Gilles Brassard in 1984) and the E91 (developed by Artur Eckert in 1991). As of this writing, six different quantum key distribution networks were in operation, largely as test and demonstration systems. Photons (elemental particles of light) traveling in fiber-optic systems have been used to date, although the People’s Republic of China has flown (in 2017) at least one spacecraft payload using laser links to connect ground stations in China and Austria in the first globe-spanning QKD network. Since the very act of attempting to sniff such a quantum key packet changes the value of the key, the potential here is profound.\n",
    "\n",
    "#### Quantum Computers as Part of Cryptanalysis Attacks\n",
    "\n",
    "Quantum computing does not use binary digits (or bits) as we’re familiar with, which store either a 0 or a 1. Every bit in a computer is in one of those two states, not both—and that bit cannot be in an undefined state, either! A qubit, or quantum bit, by contrast, exists in both the 0 and 1 states simultaneously until you observe it; then, it is said to collapse to a specific value. Without going into more detail, suffice to say that quantum computers can probably help us compute probabilistic problems far more efficiently than binary digital computers can. This could mean that a powerful quantum computer could be more effective at traditional attacks on known encryption algorithms. Mathematician Peter Shor published an algorithm in 1994 that could conceivably crack RSA’s integer factorization problem once we can build a workable quantum computer (probably one measuring in mega-qubits or giga-qubits in capacity, and hundreds of millions or billions of qu-flops, or quantum floating-point math operations per second). While such machines are still far over the horizon, the argument rages on in the blogospheres. Watch those spaces!\n",
    "\n",
    "#### AI, Machine Learning, and Cryptography\n",
    "\n",
    "Artificial intelligence (AI) is the name given to a broad set of approaches that try to make computer systems that can reason, think, solve problems, or interact with people and with each other in the same ways that healthy, rational humans do. The most familiar example of this might be natural language translation, such as that provided as a Web-based service by Google Translate. As a machine learning system, Google Translate uses a vast array of processing elements (software- and hardware-based), which form a web or mesh; that mesh looks at huge databases of phrases in the source language and, based on past experience, computes the probability that what you want is a particular phrase in the target language. If you agree with that translation, Google Translate increases the probably correct score for that pair of source and target phrases—but it still “knows” nothing about what those phrases mean to humans! (In Peter Watt’s science fiction novel Blindsight, he shows this Chinese Room translation system and the misunderstandings it can lead to, to dramatic effect!) Machine learning is done by taking such a mesh of processing elements and training it with very large sets of data—in the case of machine language translation, some of those sets would be “correct translations,” some might be “totally wrong,” and others might be “technically correct but socially ill advised,” at least statistically, that is. Each node in the mesh calculates coefficients as a result of both training and operational use. The problem with machine learning, as with many such analytics approaches, is that we humans can see that it works—it gets good answers—but we cannot explain why!\n",
    "\n",
    "Cryptanalysts might make good use of machine learning approaches, especially if they have very large datasets of ciphertext to work with and some good starting points or cribs to work from. Machine learning is already being used in traffic analysis and pattern recognition as a way to infer meaning from encrypted traffic, even traffic routed through VPNs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand the Reasons & Requirements for Cryptography\n",
    "\n",
    "```\n",
    "Understand the reasons for using cryptography as part of a secure information system. Unique identification of users, processes, files, or other information assets is a fundamental cornerstone of building any secure information system. Cryptographic techniques, from hashes through digital signatures and to encryption and decryption of data at rest, in motion, and in use, can provide a wide range of confidentiality, integrity, authentication, nonrepudiation, and availability benefits to systems designers. Modern cryptographic systems provide a wide range of choices, which allows systems builders to achieve the protection they need for costs (in money, time, effort, runtime resources, and operational complexity) commensurate with the risk.\n",
    "```\n",
    "\n",
    "```\n",
    "Explain why cryptography does not answer all information security needs. Most information systems security incidents occur because of flaws in business process design, implementation, and use; this includes the training, education, and proficiency of the human users and other workers within the organization as much as it includes the IT systems and components. Cryptography can strengthen access control, enhance the integrity and confidentiality of information, and add nonrepudiation as well—but it cannot prevent the unanticipated. Cryptography helps implement hierarchies of trust, but these are reliable only insofar as the human or supply chain aspects of those hierarchies are as trustworthy as is required.\n",
    "```\n",
    "\n",
    "```\n",
    "Explain the major vulnerabilities in various cryptographic systems and processes. The encryption and decryption keys are the most critical elements of any cryptographic system, be it symmetric, asymmetric, or hybrid, paper or electronic. If the keys cannot be protected, then all is lost. Keys can be stolen. Algorithmic weaknesses can be discovered and exploited to enable partial or complete attacks on ciphertext. Physical characteristics, such as mechanical or electrical noise, timing, stray emanations, or data remaining after part or all of an encryption operation, can be accessed, analyzed, and used to identify exploitable weaknesses.\n",
    "```\n",
    "\n",
    "### Confidentiality\n",
    "\n",
    "Suitably encrypting cleartext information makes it difficult for unauthorized readers to view, understand, or use the meaning contained in that plaintext. Encrypting information provides for its confidentiality at rest or in motion. If the information must be decrypted for use, other means must be employed to protect the information where and when it is in use.\n",
    "\n",
    "### Integrity & Authenticity\n",
    "\n",
    "Any request by a subject for access to or use of an information asset needs to be authenticated. We must be able to prove that the subject is who (or what) they claim to be, and then compare that to our controlled and protected lists or rosters of capabilities and privileges. In almost all circumstances, doing so requires the subject to send credentialing information of some kind to our systems; while in transit, that information can be intercepted for later reuse by an otherwise unauthorized subject. It can also be altered while in transit. Credentialing information is also stored (in some form) by subjects and by our authentication systems; encrypting that stored information provides protection at rest.\n",
    "\n",
    "We don't have to decrypt the credentials in order to validate that they are correct. If our authentication system stores only the encrypted (ciphertext) versions of the credentials, then a simple comparison of the ciphertext sent by the subject to the ciphertext kept on file validates or invalidates the identity of the subject. This use of digital signatures in their ciphertext form provides information protection while in use.\n",
    "\n",
    "Every communications or information storage technology is subject to error, and yet every purpose for which we use communication and information requires that information to be as error-free as possible. This fact has led to developing error detection and correction techniques - adding a parity bit to each byte or calculating a checksum digit for a block of symbols, for example. As data blocks (or messages or files) get larger and larger, error correction code (ECC) must become more complex if it is to comprehensively provide information integrity assurance. ECC can identify where an error in the associated data has occurred - which bit got flipped from a $1$ to a $0$, or which symbol was changed into another symbol - and then show us what the correct bit or symbol ought to be. \n",
    "\n",
    "ECC works by having the sender calculate the ECC ciphertext value of the message, transmitting it along with the message content (in plaintext). The receiver calculates their own ECC ciphertext value, using the same agreed-to protocol or algorithm for that ECC process, and compares it to the ECC sent with the message. Differences in sent and received ECC can then be used to find and fix the error (often by notifying the sender to resend the block).\n",
    "\n",
    "We use different names to refer to this use of cryptography to protect (or validate) the integrity of information, whether that information is at rest, in transit, or in use:\n",
    "\n",
    "* **Hashing** is the general process of using an algorithm to compute a smaller, unique value that represents the contents of the plaintext in some way. This hash value can have many uses, depending on our needs. Database systems, for example, often need to take very long strings of text (such as personal names) and map or convert them to a logical record number in a file.\n",
    "\n",
    "\n",
    "* A **digital signature** asserts that the file or message it is associated with is in fact what its name or circumstances claim it to be. Digital signatures attest to the integrity of software distribution files, for example. Digital signatures can be generated using hash algorithms or more complex encryption techniques; recipients then use the same agreed-to algorithms to validate that the signature and the file agree with each other.\n",
    "\n",
    "Nonrepudiation requires that\n",
    "\n",
    "* The identities of all parties have been authenticated.\n",
    "\n",
    "\n",
    "* All parties have proven that they have the authority or privilege to participate in the transaction.\n",
    "\n",
    "\n",
    "* The terms and conditions of the transaction exist in a form that can be recorded.\n",
    "\n",
    "\n",
    "* All of this information can be collectively or separately verified and validated to be true and correct, free from any attempts to tamper with or alter it.\n",
    "\n",
    "We assess the availability of an information system (in security terms) at two levels:\n",
    "\n",
    "* Is the system itself, and the services it provides, available and ready to perform when subjects (users or processes at their behest) request objects or other services?\n",
    "\n",
    "\n",
    "* Is the information needed by the user or requesting subject available when needed, and can it be completely and correctly output, displayed, or provided to that user or subject?\n",
    "\n",
    "Cryptography supports both of these functional needs by providing for stronger authentication and information integrity control systems. Cryptography directly contributes to making the requested information available where it is needed, when it is needed, without compromise or loss of integrity. This offers protection for information at rest and in motion.\n",
    "\n",
    "Cryptography also contributes to overall systems availability, typically as a component of strong access controls. It prevents or limits resources being exhausted (as in a denial of service attack) and can protect key systems functions by making it much harder for unauthorized subjects to perform disruptive actions.\n",
    "\n",
    "### Data Sensitivity (e.g., PII, Intellectual Property, PHI)\n",
    "### Regulatory\n",
    "```\n",
    "Know the regulatory and legal considerations for using cryptography in private business. Private businesses, in almost all jurisdictions, are subject to a variety of legal, government, and financial and insurance regulations regarding their safekeeping of information; these requirements are best summarized as CIANA, or confidentiality, integrity, availability, nonrepudiation, and authentication. Taken together, these should establish high-level, strategic needs for information security processes and systems, including cryptographic systems where applicable, for that business. Failing to do so puts customers, employees, owners, and the business at risk.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand & Support Secure Protocols\n",
    "### Services & Protocols (e.g., IPSec, TLS, S/MIME, DKIM)\n",
    "\n",
    "Transport Layer Security (TLS) provides for secure connections, but it’s hard to say exactly where in the TCP/IP or OSI protocol stacks it actually sits. It runs on top of the transport layer, and yet it is treated by many applications as if it is the transport layer. But applications that use TLS must actively take steps to initiate and control its use. It’s also further confusing, since the presentation layer is normally thought to provide encryption services for higher layers (such as the application layer in the OSI model). Perhaps it’s best to think of it as providing services at the transport layer and above, as required, and leave it at that. It has largely replaced its predecessor, Secure Sockets Layer (SSL), which was found to be vulnerable to attacks on SSL’s block cipher algorithms. (SSL also had this identity problem in terms of which layer of the protocol stack it did or didn’t belong to.)\n",
    "The TLS handshake dictates the process by which a secure session is established:\n",
    "1. The handshake starts when the client requests a TLS connection to a server, typically on port 443, or uses a specific protocol like STARTTLS when using mail or news protocols.\n",
    "2. Client and server negotiate what cipher suite (cryptographic algorithms and hash functions) will be used for the session.\n",
    "3. The server authenticates its identity, usually by using a digital certificate (which identifies the server), the (CA that authenticates that certificate), and provides the client with the server’s public encryption key.\n",
    "4. The client confirms the certificate’s validity.\n",
    "5. Session keys are generated, either by the client encrypting a random number or by using Diffie-Hellman key exchange to securely generate and exchange this random number. \n",
    "If any of these steps fail, the secure connection is not created.\n",
    "6. The session key is used to symmetrically encrypt and decrypt all subsequent data exchanges during this session, until the client or server signals the end of the session.\n",
    "\n",
    "![TLS Handshake](images/tls-handshake.png)\n",
    "\n",
    "TLS has gone through two revisions since its first introduction, and in creating TLS 1.3, RFC 8446 in August 2018 added significant improvements to TLS. One key set of changes involved strengthening forward secrecy of TLS sessions. Forward secrecy (also known as perfect forward secrecy) provides for protection of past sessions in the event that the server’s private key has been compromised. This protection is ensured by requiring a unique session key for every session a client initiates; in doing so, it offers protection against the Heartbleed exploit that affected SSL and OpenSSL, first reported in 2014. TLS 1.3 also removes support for other cryptographic and hash functions that have proven weak.\n",
    "\n",
    "The TLS cipher suite is the set of cryptographic algorithms used within TLS across its four major operational phases of key exchange and agreement, authentication, block and stream encryption, and message authentication. This suite is updated as older algorithms are shown to be too vulnerable and as new algorithms become adopted by the Internet Engineering Task Force (IETF) and the Web community. As with all algorithms and protocols involving security, the two versions of the TLS cipher suite now in common use, V1 and V1.2, are coming to their end of life. On June 30, 2018, SSL, TLS 1.1, and TLS 1.2 were declared obsolete by the IETF. The major browsers, such as Firefox, Chrome, and Bing, have been phasing them out in favor of their replacements. Be sure to check to see if your organization is using them anywhere. Note that the Payment Card Industry Data Security Standard (PCI DSS) requires use of the new versions, so any credit, debit, or payment processing systems you support may need to be double-checked as well.\n",
    "\n",
    "#### HTTPS\n",
    "\n",
    "**Hypertext Transfer Protocol Secure (or HTTPS)** is an application layer protocol in TCP/IP and the OSI model; it is simply HTTP (HyperText Transfer Protocol) using TLS (now that SSL is deprecated) to provide secure, encrypted interactions between clients and servers using hypertext. HTTPS is commonly used by Web browser applications. HTTPS provides important benefits to clients and servers alike:\n",
    "* Authentication of identity, especially of the server’s identity to the client\n",
    "* Privacy and integrity of the data transferred during the session\n",
    "* Protection against man-in-the-middle attacks that could attempt to hijack an HTTP session\n",
    "* Simplicity\n",
    "By building directly on TLS, HTTPS provides for strong encryption of the entire HTTPS session's data content or payload, using the CAs that were preinstalled in the browser by the browser application developer (Mozilla, Microsoft, DuckDuckGo, Apple, etc.). This leads to a hierarchy of trust in which the end user should trust the security of the session only if the following conditions hold true:\n",
    "* The browser software correctly implements HTTPS.\n",
    "* Certificates are correctly installed in the browser.\n",
    "* The CA vouches only for legitimate websites.\n",
    "* The certificate correctly identifies the website.\n",
    "* The negotiated encryption sufficiently protects the user’s data.\n",
    "Users should be aware that HTTPS use alone cannot protect everything about the user's Web browsing activities. HTTPS still needs resolvable IP addresses at both ends of the session; even if the content of the session is kept safe, traffic analysis of captured packets may still reveal more than some users wish. Metadata about individual page viewings may also be available for others to sniff and inspect.\n",
    "\n",
    "#### IPSec\n",
    "\n",
    "**Internet Protocol Security (IPSec)** reminds us that the first-generation Internet (or ARPANet) was built in a very different era than we’re accustomed to now. Full racks of computing and communications equipment (standing 6′ tall and perhaps 9′ wide) were needed to implement what now lives on a small part of a chip in your smartphone; the CPUs in these computers might have had 64 KB worth of RAM, and their clocks ran at 1-microsecond cycle times! Simple protocols like network address translation (NAT) turned out to be quite demanding of the CPU and memory resources on these early minicomputers. Without more processing capability and speed, early Internet Protocol (even v4) could not deliver significant security services. As a result, the ARPANet, and then the early Internet, were designed on a best-efforts basis, one that trusted users to always do what was in the best interests of the network as a whole. (After all, they reasoned, would the U.S. Navy’s computer centers want to disrupt the U.S. Air Force’s?)\n",
    "\n",
    "IPSec was developed during the late 1980s and early 1990s to provide Internet-layer (level 3) security functions, specifically the authentication and encryption of packets as they are transferred around the Internet. It needed to provide a variety of security benefits: peer authentication, sender (data origination) authentication, data integrity and confidentiality, and protection against replay attacks. IPSec can provide these services automatically, without needing application layer interaction or setup.\n",
    "\n",
    "IPSec provides two methods of operation, known as transport mode and tunnel mode. Transport mode encrypts only the payload (data content) of the IP packets being sent, which leaves all of the routing information intact. However, when transport mode uses the IPSec authentication header, services like NAT cannot operate because this will invalidate the hash value associated with the header and the routing information in it. Tunnel mode, by contrast, encrypts the entire IP packet, routing headers and all; it then encapsulates that encrypted payload into a new IP packet, with a new header. This can be used to build virtual private networks (VPNs) and can also be used for private host-to-host chat functions. Since the as-built packets from the sending system are encrypted and encapsulated for actual transmission through the network, any packet-centric services such as NAT can function correctly.\n",
    "\n",
    "IPSec can be implemented in three different ways. It’s normally built right into the operating system by including its functions within the IP stack (the set of operating systems service routines that implement the Internet Protocol in that environment). When such modification of the operating system is not desired, IPSec can be implemented as a separate set of functions that sit (in effect) between the device drivers and the operating system’s IP stack, earning it the name **bump-in-the-stack**. If external cryptoprocessors are used (that is, not under the direct, integrated control of the operating system), it’s also possible to do what’s called a **bump-in-the-wire** implementation.\n",
    "\n",
    "Originally developed for IPv4, work is in process to fully port IPSec over to IPv6.\n",
    "\n",
    "#### S/MIME\n",
    "\n",
    "Secure Multipurpose Internet Mail Extensions (S/MIME) provides presentation layer authentication, message integrity, nonrepudiation, privacy, and data security benefits to users. Using PKI, it requires the user to obtain and install their own certificate, which is then used in forming a digital signature. It provides end-to-end encryption of the email payload and thus makes it difficult for organizations to implement outgoing and incoming email inspection for malware or other contraband without performing this inspection on each end-user workstation after receipt and decryption.\n",
    "\n",
    "S/MIME has other issues, which may mean it is limited in the security it can offer to users of organizational email systems. Its signatures are detached—that is, they are not tied to the content of the message itself, so all that they authenticate is the sender’s identity and not that the sender sent the message in question. In May 2018, the EFF announced that there were critical vulnerabilities in S/MIME, particularly when forms of OpenPGP are used. EFAIL, as this vulnerability is called, can allow attackers to hide unknown plaintext within the original message (using various HTML tags). EFAIL affects many email systems, and as such, it will require much coordination between vendors to fix.\n",
    "\n",
    "#### DKIM\n",
    "Domain Keys Identified Mail (DKIM) provides an infrastructure for authenticating that an email came from the domain its address information claims it did and was thus (presumably) authorized by that domain operator or owner. It can prevent or limit the vulnerability of an organization’s email system to phishing and email spam attacks. It works by attaching a digital signature to the email message, and the receiving email service validates that signature. This confirms that the email itself (and possibly some of the attachments to it) were not tampered with during transmission, providing a degree of data integrity protection. As an infrastructure service, DKIM is not normally visible to the end users (senders or recipients), which means it does not function as an end-to-end email authentication service.\n",
    "\n",
    "Both the original RFC that proposed DKIM and work since then have identified a number of possible attack vectors and weaknesses. Some of these are related to the use of short (weak) encryption keys that can easily be brute force attacked; others relate to ways that clever spammers can spoof, misroute, forward, or otherwise misuse the email infrastructure in ways DKIM cannot help secure.\n",
    "\n",
    "#### Blockchain\n",
    "\n",
    "Think about the message digest process; it produces a hash value of a message (or file) that demonstrates that the content of that message has not been changed since the message digest was computed. A blockchain is nothing more than a series of messages, each with its own message digest, that taken together represent a transaction history about an item of interest; the message digest for the first block is computed normally, and then this is used as an input into the message digest for the next block, and so on. Thus, any attempt to make a change to the content of a block will invalidate all subsequent block-level message digests.\n",
    "\n",
    "A digital wallet uses this approach when it treats each new transaction against the wallet as a new block. The current balance in your wallet is represented by the message digest of the entire wallet, which is the sequential digest of each transaction from the first onward. When a new transaction is posted, that existing balance message digest is used as input to compute the message digest of everything associated with the transaction. (If the wallet is tracking a bank or currency account, then this might be information about the date, amount, other party, purpose, and the resulting balance in the wallet or account.)\n",
    "\n",
    "By providing strong nonrepudiation and data integrity for the transactions contained in the individual blocks, blockchains can implement digital provenance systems:\n",
    "\n",
    "* Chain of custody control, auditing, and record keeping for cyberforensics could use blockchains to irrefutably record who touched the evidence, when, how, and what they did to it.\n",
    "* Provenance systems, such as for hardware or documents, could use blockchains to prove the authenticity of the underlying data to help prove that safety-critical components (physical hardware, computer or network hardware, software, or firmware) are in fact what they claim to be.\n",
    "* Representations of any kind of value can be made extremely difficult to counterfeit.\n",
    "\n",
    "It is this last that explains the dramatic rise in the use of cryptocurrencies—the use of blockchains to represent money and to record and attest to the transactions done with that money:\n",
    "\n",
    "* The cryptocurrency miner uses significant computing power to generate a new unique cryptocurrency identifier (similar to printing a new piece of paper currency with a unique combination of serial numbers, paper security markings, etc.). This “cryptodollar” is represented by a blockchain and is stored in the mining company’s wallet.\n",
    "* Bob buys that cryptodollar from the miner, and the underlying blockchain transfers to Bob’s wallet; the new message digest reflects this transfer into Bob’s wallet. The blockchain in the miner’s wallet is updated to show this transaction.\n",
    "* Later, Bob uses that cryptodollar to buy something from Ted’s online store; the blockchain that is Bob’s wallet is updated to reflect the sell, and the blockchain that is Ted’s wallet is updated to reflect the buy.\n",
    "\n",
    "![The Blockchain Concept](images/blockchain-concept.png)\n",
    "\n",
    "If all we do is use strong message digest functions in the blockchain, we provide some pretty powerful nonrepudiation and data integrity to our cryptocurrency users. We must combine this with a suitable exchange of public and private keys to be able to protect the confidentiality of the data and to ensure that only people or processes Bob authorizes (for example) can see into Bob’s wallet, read the transaction history that is there, or initiate a new transaction.\n",
    "\n",
    "Finally, cryptocurrency systems need to address the issue of authority: who is it, exactly, that we trust as a miner of a cryptodollar? Bitcoin, for example, solves this problem by being a completely decentralized system with no central bank or authority involved. The miners are actually the maintainers of copies of the total Bitcoin ledger, which records every Bitcoin owner’s wallet information and its balance; voting algorithms provide for each distributed copy of the ledger to synchronize with the most correct copy. This maintenance function is computationally intensive, typically requiring many high-performance workstations running in parallel, and so the Bitcoin system rewards or incentivizes its miners by letting them earn a fraction of a Bitcoin as they maintain the system’s ledger.\n",
    "\n",
    "One irony of the rise in popularity and widespread adoption of blockchains and cryptocurrencies is the false perception that since money launderers, drug smugglers, and organized crime use these technologies, anyone using them must also be a criminal. Of course, nearly all criminals use money, but that does not mean that all users of money are criminals!\n",
    "\n",
    "### Common Use Cases\n",
    "### Limitations & Vulnerabilities\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand Public Key Infrastructure (PKI) Systems\n",
    "\n",
    "Three main factors separate the modern from the classical era of cryptography. The first is the switch from lexical analysis as the focus of cryptography to computationally hard problems - problems that are fairly easy to compute in one direction (given an $x$, find the corresponding $y$), but very difficult if not impossible to do in the reverse (given that $y$, find the $x$ that would generate it). The second is the near-simultaneous development, in the United States and United Kingdom, of what have been called **public key exchange protocols**. The third and perhaps most significant factor has been the explosive growth in the population of cryptographers.\n",
    "\n",
    "These factors led to the widespread adoption of hybrid approaches to cryptography, which are what make **public key encryption**, **public key infrastructures**, and our modern e-commerce world possible.\n",
    "\n",
    "```\n",
    "Explain how public key infrastructures (PKIs) are used. Public key infrastructures provide two important benefits. First, by providing a secure means to generate, distribute, authenticate, and use public and private encryption keys, PKI has made widespread use of cryptographic protection a fundamental part of business, personal, and government use of the Web and the Internet. Second, by providing a scalable, decentralized capability to digitally sign documents, files, email, or other content, PKI provides not only enhanced confidentiality and integrity of information, but also nonrepudiation protection. It also strengthens authentication mechanisms. The total is that it makes secure, reliable information more available when it is needed, where it is needed.\n",
    "```\n",
    "\n",
    "#### DES\n",
    "\n",
    "There’s an elegance to the hybrid cryptographic systems model that should not go unappreciated by the SSCP. On the one hand, we are forced to use hybrid approaches because with any given technology base, we simply do not have enough computing power to affordably encrypt everything we need to protect using end-to-end asymmetric encryption, or get that encryption and decryption done in a reasonable amount of time. On the other hand, if such hardware capabilities did exist, they’d probably be sufficient to turn the computationally infeasible problems of breaking those asymmetric algorithms into easier, more affordable opportunities! Currently, TLS 1.0 through 1.2 support six different block or stream ciphers: RC4, Triple DES, AES, IDEA, DES, and Camellia. RC4 has been proven insecure and is left in TLS to support legacy systems; Camellia has been adopted as the International Data Encryption standard by the International Standards Organization and is similar in security and design to AES. With that in mind, let’s take a closer look at DES and AES.\n",
    "\n",
    "The Data Encryption Standard (DES) was, and still is, quite controversial. It was the first published and open competition by the U.S. government for a new symmetric key block encryption algorithm. It had elements (the \"S-box\" circuits) that some claimed NSA had inserted into the design to allow DES-encrypted traffic to be decrypted by NSA without needing the original encryption key; others, in turn, insisted these S-boxes were there to defeat still other back doors built into DES. (To date, no one has been able to convincingly confirm or deny these fears; the disclosure of many NSA secrets by Edward Snowden only reheated this simmering controversy. There were many arguments about the key length, which in IBM's original proposed used 64 bit keys, and which were downsized at NSA's insistence to 56 bits. (The key actually remains 64 bits in length, but since 8 bits are used for parity checking, the effective key length is still 56 bits.) DES was made a U.S. Federal Information Processing Standard in 1977, despite much outcry within the community that it was insecure right from the start.\n",
    "\n",
    "DES used 16 rounds of processing, and its design reflects the capabilities of 1970s-era hardware. (This was the era of the first 8-bit microprocessors, and most minicomputer architectures had only a 16-bit address space.)\n",
    "\n",
    "Although many people argued whether DES was in fact breakable, the Electronic Frontier Foundation (EFF) spent $\\$250,000$ to build a custom DES Cracking Machine to prove their point. It used brute force techniques (trying every possible key) and could break DES encryption in about two days' time.\n",
    "\n",
    "Significant work was done to try to tighten up DES, including the Triple DES standard published in 1999. But it remained unsecure, and DES in all forms was finally withdrawn as a U.S. government standard in 2002 when superseded by AES.\n",
    "\n",
    "DES remains important, not because it is secure, but because in the opinion of academics, industry, and government experts, it stimulated the explosive growth of the study of cryptography by those who had no connections at all to the military and intelligence communities and their cryptographers. Even today, it is still worth studying as you begin to understand cryptography, cryptanalysis, and common attack strategies.\n",
    "\n",
    "#### DES\n",
    "\n",
    "The Advanced Encryption Standard (AES) was published by the U.S. government as FIPS Publication 197 in November 2001. It replaced DES, and although like DES it is a symmetric block encryption algorithm, it is significantly more secure. It remains in widespread use today, usually as part of hybrid encryption systems. NIST ran another open, public competition for a replacement to DES, and the Rijndael (pronounced “rhine-dahl”) cipher by Vincent Rijmen and Joan Daeman was selected as the winner. It is the first and only publicly available cipher that is approved by NSA for use on government classified information up through Top Secret when used in an NSA-approved cryptographic module.\n",
    "\n",
    "AES is a multiple-round algorithm that executes very fast in hardware or software implementations. The number of rounds is in part determined by the size of the key: 10 rounds for 128-bit keys, 12 rounds for 192-bit keys, and 14 rounds for 256-bit keys.\n",
    "\n",
    "From a math perspective, AES looks pretty simple: nothing but a series of substitutions, permutations, and exclusive ORs, done on rows and columns of matrices in which plaintext and intermediate ciphertext are held. Surprisingly, it has withstood a number of attacks (in theory and in practice).\n",
    "\n",
    "![Crypto Family Tree](images/crypto-family-tree.png)\n",
    "\n",
    "### Fundamental Key Management Concepts (e.g., Key Rotation, Key Composition, Key Creation, Exchange, Revocation, Escrow)\n",
    "\n",
    "```\n",
    "Explain what key management is, what different approaches can be used, and the issues with key management. Key management is the process of creating encryption and decryption keys and then issuing, distributing, or sending them to users of the cryptographic system in question. The cryptographic keys are the fundamental secret that must be protected—all else, from systems design and usage through its fundamental algorithms, is known or will be easily known by one’s adversaries. Keys must be distributed in ways that prevent loss or disclosure, and they need to be destroyed or zeroized if users leave the network, if keys are partially compromised, or as a routine security measure. Keys can be distributed as physical documents or in electronic message format; both are subject to compromise, corruption, and loss, and typically such key systems (if based on symmetric algorithms) cannot self-authenticate a sender or recipient. Public key infrastructures do not actually distribute keys; rather, they provide for sender and recipient to co-generate a unique, private session key, which is used only for that session’s communication; these require asymmetric (public and private) keys have been generated for each user, typically authenticated by certificates.\n",
    "```\n",
    "\n",
    "#### Diffie-Hellman-Merkle Public Key Exchange\n",
    "\n",
    "Key exchange is not about exchanging secret information between the parties; rather, it is about \"creating\" a shared key to use for subsequent encrypted sharing of secrets. Furthermore, it's important to realize that the \"public\" part of public key exchange is that you can quite literally publish parts of that key exchange without compromising the security of the encryption it supports. Whitfield Diffie and Martin Hellman first showed that public key exchange requires the use of what they called trapdoor functions - a class of mathematical problems that are easy to do in one direction (like falling through a trapdoor in the floor) but extremely difficult if not impossible to do in the other direction.\n",
    "\n",
    "* Classical cryptographic systems depend upon **key distribution** systems to ensure that all known, authenticated, and trustworthy parties on the system have current encryption keys. Key distribution is the passing of secret information - the keys - from the key originator and controller to the parties who will use it.\n",
    "\n",
    "\n",
    "* **Key exchange** systems start with the presumption that parties do not know each other, and have no a priori reason to trust each other. They achieve this trust, and therefore can share in a secure, encrypted conversation, by generating their session key together, and keeping that session key secret to themselves.\n",
    "\n",
    "In both cases, the underlying **key infrastructure** is the collection of systems, communications pathways, protocols, algorithms, and processes (people-facing or built into software and hardware) that make key distribution or exchange work effectively and reliability.\n",
    "\n",
    "#### RSA Encryption & Key Exchange\n",
    "\n",
    "Like Diffie-Hellman, RSA uses the properties of modulo arithmetic applied to exponentiation of very large integers, where the modulus is also a very large prime number.\n",
    "\n",
    "#### ElGamal Encryption\n",
    "\n",
    "ElGamal provides for asymmetric encryption of keys previously used in symmetric encryption schemes. ElGamal also proposed a digital signature mechanism that allows third parties to confirm the authenticity of a message signed with it.\n",
    "\n",
    "Some hybrid encryption systems use ElGamal to encrypt the symmetric keys used to encrypt message content. It is vulnerable to the chosen-ciphertext attack, in which the attacker somehow tricks or spoofs a legitimate user (an oracle) into decrypting an arbitrary message block and then sharing those results with the attacker. (Variations on this kind of attack were first known as **lunchtime attacks**, since the user's machine was assumed to be available while they were at lunch.) ElGamal does provide padding and other means to limit this vulnerability.\n",
    "\n",
    "#### Digital Signature\n",
    "\n",
    "```\n",
    "Explain how cryptography is used to support digital signatures and what benefits you gain from using digital signatures. Asymmetric keys provide a way to digitally sign a file, an email, or a document. Typically this involves calculating a cryptographic hash of the input file, and combining it with the originator’s private key via a decryption process; the result is called the sender’s digital signature of that file or document. Recipients use the matching encryption process on that digital signature, using the sender’s public signature, to produce a received hash value, while also locally computing a hash of the received file. If these match, then the sender’s identity has been validated. Digitally signing files assures recipients that software updates, transaction files, or important documents have not been altered in storage or transmission. This provides enhanced data integrity and nonrepudiation and can do so across space (sender to recipient) and across time (validating that files placed in storage have not been corrupted between the time they were created and the time they are retrieved for use, be that milliseconds or months).\n",
    "```\n",
    "\n",
    "Suppose our friend Carol wishes to send a message to Bob, but in doing so, she needs to prove to Bob that the message is inarguably from her and not from some imposter:\n",
    "\n",
    "1. Carol produces a strong hash of the message content.\n",
    "2. Carol decrypts that hash value, using the trapdoor function and her private key. This new value is her digital signature.\n",
    "3. Carol sends the message and her digital signature to Bob.\n",
    "4. Bob encrypts Carol's digital signature, using the same trapdoor algorithm and Carol's public signature, to produce the signed hash value.\n",
    "5. Bob uses the same hash function to produce a comparison hash of the message he received (not including the signature). If this matches the value he computed in step $4$, he has proven that Carol (who is the only one who knows her private key) is the only one who could have sent that message.\n",
    "\n",
    "HTTPS actually says \"use HTTP over secure sockets\", which either meant \"over SSL\" or \"over TLS\".\n",
    "\n",
    "### Web of Trust (WOT) (e.g., PGP, GPG)\n",
    "\n",
    "```\n",
    "Explain the difference between hierarchies of trust and webs of trust. Both concepts strive to establish associations or logical networks of entities. The topmost node of such a network, its trust anchor, confers trust upon intermediaries, which can then assert their trust to end (leaf) nodes. In hierarchies of trust, certificate authorities are the trusted anchors, which can issue certificates to intermediaries, which can issue certificates to the leaf nodes. End users, seeking to validate the trustworthiness of a certificate, infer that a certificate from a trusted end (leaf) node is trustworthy if the intermediary that issued it is, on up to the anchor. Webs of trust, by contrast, involve peer-to-peer trust relationships that do not rely on central certificate authorities as the anchors. Hierarchies of trust are much more scalable (to billions of certificates in use) than webs of trust. Both systems have drawbacks and issues, particularly with respect to certificate revocation, expiration, or the failure of a node to maintain trustworthiness.\n",
    "```\n",
    "\n",
    "In information and communications systems terms, the foremost token of trust is a **certificate** that asserts that the identity of the certificate holder and the public key associated with that certificate are linked or bound with each other. This gives rise to two different concepts of how trust conferred by one node upon another can be scaled up to larger numbers of nodes:\n",
    "\n",
    "* A **hierarchy of trust** exists when a single node is recognized as the authority for asserting or conferring trust. This conferring of trust can be delegated downward (made transitive) by that trust authority conferring a special status to a set of intermediate nodes, each of which can act as a trust authority for other intermediary nodes or end user nodes (recipients of trust), which (in tree structure terms) are the leaf nodes. The **trust anchor** is the trust authority, as the root of this tree of trust, conferring trust downward through any number of intermediaries, to the leaf nodes. Hierarchies of trust resemble forests of trees (in data structure terms!), with one root branching out to start many sub-trees, which may further branch, until finally we reach the leaf nodes at the very tip of each twig.\n",
    "* A **certificate authority (CA)** is the anchor node of a hierarchy of trust, issuing the certificates that bind individual identities with their corresponding public keys.\n",
    "* A **web of trust** has no designated or accepted single authority for trust, and acts in peer-to-peer fashion to establish chains of trust.\n",
    "\n",
    "In both hierarchies of trust and webs of trust, any given node can be a member of one or more trust relationships, and therefore be a member of one or more chains or webs of trust.\n",
    "\n",
    "In hierarchies of trust, end users, seeking to validate the trustworthiness of a certificate, infer that a certificate from a trusted end (leaf) node is trustworthy if the intermediary who issued it is, on up to the anchor. Webs of trust, by contrast, involve peer-to-peer trust relationships that do not rely on central certificate authorities as the anchors. Hierarchies of trust are much more scalable (to billions of certificates in use) than webs of trust. Both systems have drawbacks and issues, particularly with respect to certificate revocation, expiration, or the failure of a node to maintain trustworthiness. (The details of those issues are beyond the scope of the SSCP exam, but you do need to be aware that these issues exist and are not straightforward.)\n",
    "\n",
    "TLS, and secure HTTP (HTTPS), require the use of a certificate, granted by a certificate authority (CA). SSL and TLS established what was called the chain of trust, shown in Figure 7.4. The chain of trust starts with the CA itself generating a self-signed certificate, called a **root certificate**; this anchors the **chain of trust**. This root certificate can be used to generate and authenticate any number of intermediate certificates, which can also be used to authenticate (sign) other intermediate certificates. The end-entity, or end-user certificate, is the distant end of the chain of trust; it authenticates the end user’s identity and is signed by an intermediate certificate issuer (or, hypothetically, it could be signed by the root authority). End-entity or leaf certificates (borrowing from tree structure terminology) are terminal - they cannot be used to sign other certificates of any kind.\n",
    "\n",
    "![Chains of Trust](images/chains-of-trust.png)\n",
    "\n",
    "Certificates of this kind allow browsers or other client-side programs to use a certification path validation algorithm, which has to validate that (a) the subject of the certificate matches the host name being connected to, and (b) the certificate is signed by a trusted authority, has not been revoked, and has not expired. \n",
    "\n",
    "![Certification Path Validation Algorithm](images/certification-path-validation-algorithm.png)\n",
    "\n",
    "In 2008, the IETF published updated versions of the X.509 standard, which define these certificates and the protocols for their use.\n",
    "\n",
    "As it turns out, anyone can become a self-authenticating certificate authority! This could be very helpful if your organization requires an isolated LAN in which certificate-based services are necessary but all use of those services stays within that LAN, for example. To become part of the world-spanning infrastructure, however, those wishing to become CAs have to have their certificate implementations adopted by the major Web browsers, which means getting their certificates bundled in with Edge, Firefox, Chrome, Safari, or Opera, for example. In fact, one of the key elements of these major vendor root certificate programs is that by becoming a root certificate member with them, your company adds significant value to their user community. CA applicants then have to go through rigorous technical demonstrations of their domains and their services. Each of those vendors has its own standards and processes to ensure that as a would-be CA, your company is not about to harm their reputation or the reputations or interests of their customers, partners, clients, and users worldwide.\n",
    "\n",
    "What this all boils down to is that if you want to be an anchor of many trust chains, we, the rest of the Internet-using world, really do require that you prove your trustworthiness, your reliability, and your integrity to us. This may be why the four CAs with the largest market share between them are IdenTrust, Comodo, DigiCert, and GoDaddy, according to W3Techs surveys. In 2017, Google and Mozilla rejected Symantec’s certificates from their browser bundles, citing numerous repeated violations of trust—including incorrect or unjustified issuance of over 30,000 HTTPS certificates. Some of this involved issuing free “domain validated” certificates, thought to be a great way to stimulate further small business development; in reality, it made it trivially easy for malicious sites to spring into action, typically with phishing attacks on unsuspecting targets. Prior to this, Symantec had been the market leader; that same year, DigiCert acquired Symantec.\n",
    "\n",
    "The certificate validation process also demonstrates another important aspect of cybersecurity and cryptography that SSCPs must deal with every day: every system your organization uses is the result of an information technology supply chain, a chain that runs from designers and developers, through subsystems vendors and parts suppliers, to end-user sales and service, and then into your own organization’s technology support staff. Every step of that process is a potential opportunity for threats to find vulnerabilities and exploit them. In fact, one definition of an advance persistent threat is that it is an organization or entity that looks at as much of the IT supply chain as it possibly can, seeking points of entry or influence.\n",
    "\n",
    "#### Pretty Good Privacy\n",
    "In much the same timeframe in which Rivest, Shamir, and Adleman were battling with the U.S. government over making powerful encryption available to private citizens, businesses, and others, another battle started to rage over a software package called Pretty Good Privacy. PGP had been created by Phil Zimmerman, a long-time antinuclear activist, in 1991; he released it into the wild via friend who posted it in Usenet and on Peacenet, which was an ISP that focused on supporting various grass-roots political and social movements around the world. Almost immediately, the government realized that PGP’s use of 128-bit (and larger) encryption keys violated the 40-bit limit established for export of munitions as defined in the Militarily Critical Technologies List; the government began a criminal investigation of Zimmerman, his associates, and PGP. Zimmerman then published the source code of PGP and its underlying symmetric encryption algorithm (the Bassomatic) in book form (via MIT Press), which was protected as free speech under the First Amendment of the U.S. Constitution. By 1996, the government backed down, and did not bring criminal charges against Zimmerman.\n",
    "\n",
    "PGP uses a web of trust concept, but does embody a concept of key servers that can act as a decentralized mesh of repositories and clearinghouses. Its design provides not only for encryption of data in motion, but also for data at rest.\n",
    "Initially, PGP as a software product allowed end users to encrypt any content, whether that was a file or the body of an email message. Various distributions used different encryption algorithms, such as ElGamal, DSA, and CAST-128. The designs and source code of PGP have moved through a variety of commercial products, including the z/OS encryption facility for the IBM Z mainframe computer family.\n",
    "\n",
    "Described by some as being “the closest you’re likely to get to military-grade encryption,” as of this writing there do not seem to be known methods, computational or cryptographic, for breaking PGP encryption. Wikipedia and other sources cite a 2006 case in which U.S. Customs agents could not break PGP-encrypted content, suspected to be child pornography, on a laptop they had seized. A bug in certain implementations of PGP was discovered in May 2018, which under certain circumstances could lead to disclosing the plaintext associated with a given ciphertext of emails encrypted by these email variants.\n",
    "Since its inception, PGP has evolved in several directions. It still is available in various free software and open source distributions; it’s also available in a variety of commercial product forms.\n",
    "\n",
    "#### OpenPGP\n",
    "A variety of efforts are underway to bring PGP and its use of different algorithms into an Internet set of standards. Some of these standards support the use of PGP by email clients; others look to specify the encryption suites used by PGP in different implementations. RFC 4880 is the main vehicle for change within the IETF for bringing PGP into the formally accepted Internet baseline. There is also work ongoing to develop a PGP-compliant open source library of JavaScript routines for use in Web applications that want to use PGP when supported by browsers running the app.\n",
    "\n",
    "#### GPG\n",
    "GNU Privacy Guard (GPG) is part of the GNU project, which aims to provide users with what the project calls the four essential freedoms that software uses should have and enjoy. GPG provides a free and open source implementation of the OpenPGP standard, consistent with RFC 4800. It provides key management and access modules, support for S/MIME and SSH, and tools for easy integration into a variety of applications. It’s also available as Gpg4win, which provides GPG capabilities for Microsoft Windows systems, including a plugin for Outlook email.\n",
    "\n",
    "Free, in the context of free software, should be thought of in the same way as free speech rather than free beer, as explained on https://www.gnu.org/home.en.html. Free software advocates assert that the conflux of corporate and government interests are all too willing to sacrifice individual freedom of choice, including the freedom to speak or to keep something private. Without freely available source code for important infrastructure elements such as GPG and the GNU variant of Linux, they argue, individuals have no real way to know what software to trust or what information and communications they can rely upon. Whether you agree or disagree with their politics, GPG and other free software systems are increasingly becoming common elements in the IT architectures that SSCPs need to support and defend.\n",
    "It is interesting to note that the German government initially donated 250,000 Deutschmarks (about $132,000) to the development and support of GPG."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
